{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd915365",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d869b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a94160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts.\n",
    "Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.\n",
    "A small river named Duden flows by their place and supplies it with the necessary regelialia.\n",
    "It is a paradisematic country, in which roasted parts of sentences fly into your mouth.\n",
    "Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.\n",
    "The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didnâ€™t listen.\n",
    "She packed her seven versalia, put her initial into the belt and made herself on the way.\n",
    "When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937c1ea",
   "metadata": {},
   "source": [
    "Preprocessing text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3c1ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['far far away behind the word mountains far from the countries vokalia and consonantia there live the blind texts ',\n",
       " 'separated they live in bookmarksgrove right at the coast of the semantics a large language ocean ',\n",
       " 'a small river named duden flows by their place and supplies it with the necessary regelialia ',\n",
       " 'it is a paradisematic country in which roasted parts of sentences fly into your mouth ',\n",
       " 'even the all powerful pointing has no control about the blind texts it is an almost unorthographic life one day however a small line of blind text by the name of lorem ipsum decided to leave for the far world of grammar ',\n",
       " 'the big oxmox advised her not to do so because there were thousands of bad commas wild question marks and devious semikoli but the little blind text didn t listen ',\n",
       " 'she packed her seven versalia put her initial into the belt and made herself on the way ',\n",
       " 'when she reached the first hills of the italic mountains she had a last view back on the skyline of her hometown ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = nltk.sent_tokenize(text)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower()\n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i])\n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf92e43",
   "metadata": {},
   "source": [
    "Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3553b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'far': 4,\n",
       " 'away': 1,\n",
       " 'behind': 1,\n",
       " 'the': 17,\n",
       " 'word': 1,\n",
       " 'mountains': 2,\n",
       " 'from': 1,\n",
       " 'countries': 1,\n",
       " 'vokalia': 1,\n",
       " 'and': 4,\n",
       " 'consonantia': 1,\n",
       " 'there': 2,\n",
       " 'live': 2,\n",
       " 'blind': 4,\n",
       " 'texts': 2,\n",
       " 'separated': 1,\n",
       " 'they': 1,\n",
       " 'in': 2,\n",
       " 'bookmarksgrove': 1,\n",
       " 'right': 1,\n",
       " 'at': 1,\n",
       " 'coast': 1,\n",
       " 'of': 8,\n",
       " 'semantics': 1,\n",
       " 'a': 5,\n",
       " 'large': 1,\n",
       " 'language': 1,\n",
       " 'ocean': 1,\n",
       " 'small': 2,\n",
       " 'river': 1,\n",
       " 'named': 1,\n",
       " 'duden': 1,\n",
       " 'flows': 1,\n",
       " 'by': 2,\n",
       " 'their': 1,\n",
       " 'place': 1,\n",
       " 'supplies': 1,\n",
       " 'it': 3,\n",
       " 'with': 1,\n",
       " 'necessary': 1,\n",
       " 'regelialia': 1,\n",
       " 'is': 2,\n",
       " 'paradisematic': 1,\n",
       " 'country': 1,\n",
       " 'which': 1,\n",
       " 'roasted': 1,\n",
       " 'parts': 1,\n",
       " 'sentences': 1,\n",
       " 'fly': 1,\n",
       " 'into': 2,\n",
       " 'your': 1,\n",
       " 'mouth': 1,\n",
       " 'even': 1,\n",
       " 'all': 1,\n",
       " 'powerful': 1,\n",
       " 'pointing': 1,\n",
       " 'has': 1,\n",
       " 'no': 1,\n",
       " 'control': 1,\n",
       " 'about': 1,\n",
       " 'an': 1,\n",
       " 'almost': 1,\n",
       " 'unorthographic': 1,\n",
       " 'life': 1,\n",
       " 'one': 1,\n",
       " 'day': 1,\n",
       " 'however': 1,\n",
       " 'line': 1,\n",
       " 'text': 2,\n",
       " 'name': 1,\n",
       " 'lorem': 1,\n",
       " 'ipsum': 1,\n",
       " 'decided': 1,\n",
       " 'to': 2,\n",
       " 'leave': 1,\n",
       " 'for': 1,\n",
       " 'world': 1,\n",
       " 'grammar': 1,\n",
       " 'big': 1,\n",
       " 'oxmox': 1,\n",
       " 'advised': 1,\n",
       " 'her': 4,\n",
       " 'not': 1,\n",
       " 'do': 1,\n",
       " 'so': 1,\n",
       " 'because': 1,\n",
       " 'were': 1,\n",
       " 'thousands': 1,\n",
       " 'bad': 1,\n",
       " 'commas': 1,\n",
       " 'wild': 1,\n",
       " 'question': 1,\n",
       " 'marks': 1,\n",
       " 'devious': 1,\n",
       " 'semikoli': 1,\n",
       " 'but': 1,\n",
       " 'little': 1,\n",
       " 'didn': 1,\n",
       " 't': 1,\n",
       " 'listen': 1,\n",
       " 'she': 3,\n",
       " 'packed': 1,\n",
       " 'seven': 1,\n",
       " 'versalia': 1,\n",
       " 'put': 1,\n",
       " 'initial': 1,\n",
       " 'belt': 1,\n",
       " 'made': 1,\n",
       " 'herself': 1,\n",
       " 'on': 2,\n",
       " 'way': 1,\n",
       " 'when': 1,\n",
       " 'reached': 1,\n",
       " 'first': 1,\n",
       " 'hills': 1,\n",
       " 'italic': 1,\n",
       " 'had': 1,\n",
       " 'last': 1,\n",
       " 'view': 1,\n",
       " 'back': 1,\n",
       " 'skyline': 1,\n",
       " 'hometown': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count = {}\n",
    "for data in dataset:\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for word in words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "word2count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d392f",
   "metadata": {},
   "source": [
    "Most frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28bd328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1a22a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'of',\n",
       " 'a',\n",
       " 'far',\n",
       " 'and',\n",
       " 'blind',\n",
       " 'her',\n",
       " 'it',\n",
       " 'she',\n",
       " 'mountains',\n",
       " 'there',\n",
       " 'live',\n",
       " 'texts',\n",
       " 'in',\n",
       " 'small',\n",
       " 'by',\n",
       " 'is',\n",
       " 'into',\n",
       " 'text',\n",
       " 'to',\n",
       " 'on',\n",
       " 'away',\n",
       " 'behind',\n",
       " 'word',\n",
       " 'from',\n",
       " 'countries',\n",
       " 'vokalia',\n",
       " 'consonantia',\n",
       " 'separated',\n",
       " 'they',\n",
       " 'bookmarksgrove',\n",
       " 'right',\n",
       " 'at',\n",
       " 'coast',\n",
       " 'semantics',\n",
       " 'large',\n",
       " 'language',\n",
       " 'ocean',\n",
       " 'river',\n",
       " 'named',\n",
       " 'duden',\n",
       " 'flows',\n",
       " 'their',\n",
       " 'place',\n",
       " 'supplies',\n",
       " 'with',\n",
       " 'necessary',\n",
       " 'regelialia',\n",
       " 'paradisematic',\n",
       " 'country',\n",
       " 'which',\n",
       " 'roasted',\n",
       " 'parts',\n",
       " 'sentences',\n",
       " 'fly',\n",
       " 'your',\n",
       " 'mouth',\n",
       " 'even',\n",
       " 'all',\n",
       " 'powerful',\n",
       " 'pointing',\n",
       " 'has',\n",
       " 'no',\n",
       " 'control',\n",
       " 'about',\n",
       " 'an',\n",
       " 'almost',\n",
       " 'unorthographic',\n",
       " 'life',\n",
       " 'one',\n",
       " 'day',\n",
       " 'however',\n",
       " 'line',\n",
       " 'name',\n",
       " 'lorem',\n",
       " 'ipsum',\n",
       " 'decided',\n",
       " 'leave',\n",
       " 'for',\n",
       " 'world',\n",
       " 'grammar',\n",
       " 'big',\n",
       " 'oxmox',\n",
       " 'advised',\n",
       " 'not',\n",
       " 'do',\n",
       " 'so',\n",
       " 'because',\n",
       " 'were',\n",
       " 'thousands',\n",
       " 'bad',\n",
       " 'commas',\n",
       " 'wild',\n",
       " 'question',\n",
       " 'marks',\n",
       " 'devious',\n",
       " 'semikoli',\n",
       " 'but',\n",
       " 'little',\n",
       " 'didn']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words = heapq.nlargest(100, word2count, key = word2count.get)\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c232e",
   "metadata": {},
   "source": [
    "Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "170db62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      "  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for data in dataset:\n",
    "    vector=[]\n",
    "    for word in freq_words:\n",
    "        if word in nltk.word_tokenize(data):\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)\n",
    "X = np.asarray(X)\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
